//-----------------------------------------------------------------------------
// SP_LLC-cache.sm
//-----------------------------------------------------------------------------
// This models LLC cache
//
// Author: Tuan Ta
// Date  : 19/07/03

machine(MachineType:L2Cache, "SP LLC cache")
    : CacheMemory* cacheMemory;
      Cycles cache_resp_latency := 12;
      Cycles to_memory_controller_latency := 1;

      MessageBuffer* requestToLLC,    network = "From", virtual_network = "1", vnet_type = "request";
      MessageBuffer* responseFromLLC, network = "To",   virtual_network = "0", vnet_type = "response";
      MessageBuffer* responseFromMemory;
      
{
  //---------------------------------------------------------------------------
  // Global state... registers in this mem controller
  //---------------------------------------------------------------------------
  
  // counters in the mem controller
  int _xCnt := 0;
  int _yCnt := 0;
      
  // prevent both inports from starting vector op while other is in progress
  bool _vecFromMem := false;
  bool _vecFromLLC := false;
  
  //---------------------------------------------------------------------------
  // States
  //---------------------------------------------------------------------------

  state_declaration(State, desc = "", default = "L2Cache_State_I") {
    I,     AccessPermission:Invalid,     desc = "Not present/invalid";
    IV,    AccessPermission:Busy,        desc = "Waiting for data";
    IM,    AccessPermission:Busy,        desc = "Waiting for data";
    V,     AccessPermission:Read_Write,  desc = "Valid & clean";
    M,     AccessPermission:Read_Write,  desc = "Valid & dirty";
    MI,    AccessPermission:Busy,        desc = "Waiting for writeback ACK";
    IV_LL, AccessPermission:Busy,        desc = "Waiting for data (LL request)";
    IA,    AccessPermission:Busy,        desc = "Waiting for data (ATOMIC request)";
  }

  //---------------------------------------------------------------------------
  // Events
  //---------------------------------------------------------------------------

  enumeration(Event, desc = "Cache events") {
    // from scratchpads
    READ,   desc = "A READ request arrives";
    VREAD,  desc = "A Vector READ request is being processed";
    WRITE,  desc = "A WRITE request arrives";
    LL,     desc = "A LL request arrives";
    SC,     desc = "A SC request arrives";
    ATOMIC, desc = "An ATOMIC request arrives";
    Repl,   desc = "Replacement";

    // from memory
    Memory_Data,  desc = "Fetched data from memory arrives";
    VMemory_Data, desc = "Fetched data from memory arrives and do vec op"; // kinda hacky
    Memory_Ack,   desc = "Writeback Ack from memory arrives";
  }

  //---------------------------------------------------------------------------
  // Cache entry
  //---------------------------------------------------------------------------

  structure(Entry, desc = "...", interface = "AbstractCacheEntry") {
    State CacheState,     desc = "Cache state";
    DataBlock DataBlk,    desc = "Data in the block";
    WriteMask writeMask,  desc = "Dirty byte mask";
    MachineID LLSC_owner, desc = "Owner of LLSC lock";
  }

  //---------------------------------------------------------------------------
  // TBE entry
  //---------------------------------------------------------------------------

  // Data stored from a packet once taken out of RequestBuf. Needed to finish req when mem resp arrives
  structure(TBE, desc = "...") {
    State     TBEState,   desc = "Transient state";
    DataBlock DataBlk,    desc = "Data for the block";
    WriteMask writeMask,  desc = "Dirty byte mask";
    MachineID Requestor,  desc = "Requestor's ID";
    int       SeqNum,     desc = "Sequence number";
    int       XDim,       desc = "X dimension to access for";
    int       YDim,       desc = "Y dimension to access for";
    Addr      WordAddress,desc = "Word address of element request";
  }

  structure(TBETable, external = "yes") {
    TBE lookup(Addr);
    void allocate(Addr);
    void deallocate(Addr);
    bool isPresent(Addr);
  }

  //---------------------------------------------------------------------------
  // Structures
  //---------------------------------------------------------------------------

  TBETable TBEs, template="<L2Cache_TBE>", constructor="m_number_of_TBEs";

  //---------------------------------------------------------------------------
  // Prototypes
  //---------------------------------------------------------------------------

  Tick clockEdge();
  Cycles ticksToCycles(Tick t);
  void set_cache_entry(AbstractCacheEntry a);
  void unset_cache_entry();
  void set_tbe(TBE b);
  void unset_tbe();
  void wakeUpAllBuffers();

  //---------------------------------------------------------------------------
  // Functions
  //---------------------------------------------------------------------------

  Entry getCacheEntry(Addr address), return_by_pointer="yes" {
    return static_cast(Entry, "pointer", cacheMemory.lookup(address));
  }

  State getState(TBE tbe, Entry cache_entry, Addr addr) {
    if (is_valid(tbe)) {
      return tbe.TBEState;
    } else if (is_valid(cache_entry)) {
      return cache_entry.CacheState;
    } else {
      return State:I;
    }
  }

  void setState(TBE tbe, Entry cache_entry, Addr addr, State state) {
    if (is_valid(tbe)) {
      tbe.TBEState := state;
    }

    if (is_valid(cache_entry)) {
      cache_entry.CacheState := state;
    }
  }

  AccessPermission getAccessPermission(Addr addr) {
    TBE tbe := TBEs[addr];

    if (is_valid(tbe)) {
      return L2Cache_State_to_permission(tbe.TBEState);
    }

    Entry cache_entry := getCacheEntry(addr);

    if (is_valid(cache_entry)) {
      return L2Cache_State_to_permission(cache_entry.CacheState);
    }

    return AccessPermission:NotPresent;
  }

  void setAccessPermission(Entry cache_entry, Addr addr, State state) {
    if (is_valid(cache_entry)) {
      cache_entry.changePermission(L2Cache_State_to_permission(state));
    }
  }

  bool functionalRead(Addr addr, Packet *pkt) {
    TBE tbe := TBEs[addr];
    Entry cache_entry := getCacheEntry(addr);

    if (is_valid(tbe)) {
      return testAndRead(addr, tbe.DataBlk, pkt);
    } else if (is_valid(cache_entry)) {
      return testAndRead(addr, getCacheEntry(addr).DataBlk, pkt);
    } else {
      functionalMemoryRead(pkt);
      return true;
    }
  }

  int functionalWrite(Addr addr, Packet *pkt) {
    int num_functional_writes := 0;
    TBE tbe := TBEs[addr];
    Entry cache_entry := getCacheEntry(addr);

    if (is_valid(tbe)) {
      num_functional_writes := num_functional_writes +
                        testAndWrite(addr, tbe.DataBlk, pkt);
    } else if (is_valid(cache_entry)) {
      num_functional_writes := num_functional_writes +
                        testAndWrite(addr, getCacheEntry(addr).DataBlk, pkt);
    } else if (version == intToID(0)) {
      // only one L2 bank needs to do the functional write to memory, so let
      // the first L2 do it.
      num_functional_writes := num_functional_writes +
                        functionalMemoryWrite(pkt);
    }

    return num_functional_writes;
  }

  bool isCacheEntryPresent(Addr addr) {
    return cacheMemory.isTagPresent(addr);
  }
  
  int getLinearIdx(int xDim, int yDim) {
    int xIdx := xDim - _xCnt - 1;
    int yIdx := yDim - _yCnt - 1;
    int idx  := xIdx + yIdx * xDim;
    return idx;
  }

  //---------------------------------------------------------------------------
  // Network ports
  //---------------------------------------------------------------------------

  // Responses to CPU side
  out_port(responseNetwork_out, LLCResponseMsg, responseFromLLC);

  // Requests coming from CPU side
  in_port(requestNetwork_in, LLCRequestMsg, requestToLLC) {
    if (requestNetwork_in.isReady(clockEdge())) {
      peek(requestNetwork_in, LLCRequestMsg) {

        //Addr LineAddress := makeLineAddress(in_msg.WordAddress);
        //assert(LineAddress == in_msg.LineAddress); why isn't this the same!!
        Addr LineAddress := in_msg.LineAddress;
        
        // sanity check
        assert(in_msg.XDim > 0 && in_msg.YDim > 0);
        
        Entry cache_entry := getCacheEntry(LineAddress);
        
        DPRINTF(RubySlicc, "%s arrived\n", in_msg);

        if (is_invalid(cache_entry) &&
            cacheMemory.cacheAvail(LineAddress) == false) {
          // No available cache line for this address -> trigger cache
          // replacement
          Addr victim := cacheMemory.cacheProbe(LineAddress);
          trigger(Event:Repl, victim, getCacheEntry(victim), TBEs.lookup(victim));
        } else {
          // There's an available slot
          TBE tbe := TBEs[LineAddress];

          if (in_msg.Type == LLCRequestType:READ) {
            // check whether this is the last read for this request
            // the last read will be done like a normal read (update cache policy, profile, etc..)
            // any other read will just send data and increment vector counter
            
            // note the icache can also send these messages and won't have a valid xdim, ydim
            
            bool lastAccess := ((in_msg.XDim <= 1 && in_msg.YDim <= 1) || // check if even vector load (could just encode in msg type)
                              (_xCnt == in_msg.XDim - 1 && _yCnt == in_msg.YDim - 1));
            
            if (lastAccess) {
              trigger(Event:READ, LineAddress, cache_entry, tbe);
            } else if (!_vecFromMem) {
              trigger(Event:VREAD, LineAddress, cache_entry, tbe);
            }
            else {
              // can't use vec counter, so do nothing until finished
            }
            
            trigger(Event:READ, LineAddress, cache_entry, tbe);
          } else if (in_msg.Type == LLCRequestType:WRITE) {
            trigger(Event:WRITE, LineAddress, cache_entry, tbe);
          } else if (in_msg.Type == LLCRequestType:LL) {
            trigger(Event:LL, LineAddress, cache_entry, tbe);
          } else if (in_msg.Type == LLCRequestType:SC) {
            trigger(Event:SC, LineAddress, cache_entry, tbe);
          } else if (in_msg.Type == LLCRequestType:ATOMIC) {
            trigger(Event:ATOMIC, LineAddress, cache_entry, tbe);
          } else {
            error("Invalid message");
          }
        }
      }
    }
  }

  // Responses from memory controller
  in_port(memQueue_in, MemoryMsg, responseFromMemory) {
    if (memQueue_in.isReady(clockEdge())) {
      peek(memQueue_in, MemoryMsg, block_on = "addr") {
        TBE tbe := TBEs.lookup(in_msg.addr);
        assert(is_valid(tbe));

        Entry cache_entry := getCacheEntry(in_msg.addr);

        if (in_msg.Type == MemoryRequestType:MEMORY_READ) {
          assert(is_valid(cache_entry));
          
          bool lastAccess := ((tbe.XDim <= 1 && tbe.YDim <= 1) || // check if even vector load (could just encode in msg type)
                              (_xCnt == tbe.XDim - 1 && _yCnt == tbe.YDim - 1));
            
          if (lastAccess) {
            trigger(Event:Memory_Data, in_msg.addr, cache_entry, tbe);
          } else if (!_vecFromLLC) {
            trigger(Event:VMemory_Data, in_msg.addr, cache_entry, tbe);
          }
          else {
            // can't use vec counter, so do nothing until finished
          }
          
          
          trigger(Event:Memory_Data, in_msg.addr, cache_entry, tbe);
        } else if (in_msg.Type == MemoryRequestType:MEMORY_WB) {
          trigger(Event:Memory_Ack, in_msg.addr, cache_entry, tbe);
        } else {
          error("Invalid message");
        }
      }
    }
  }

  //---------------------------------------------------------------------------
  // Actions
  //---------------------------------------------------------------------------

  action(atb_allocateTBE, "atb", desc = "Allocate TBE") {
    TBEs.allocate(address);
    set_tbe(TBEs[address]);
  }

  action(dtb_deallocateTBE, "dtb", desc = "Deallocate TBE") {
    TBEs.deallocate(address);
    unset_tbe();
  }

  action(acb_allocateCacheBlock, "acb", desc = "Allocate cache block") {
    if (is_valid(cache_entry) == false) {
      set_cache_entry(cacheMemory.allocate(address, new Entry));
      cache_entry.LLSC_owner := createMachineID(MachineType:NULL, intToID(0));
    }
  }

  action(imr_issueMemReadRequest, "imr", desc = "Queue memory read request") {
    peek(requestNetwork_in, LLCRequestMsg) {
      queueMemoryRead(in_msg.Requestor, address, to_memory_controller_latency);
    }
  }

  action(imw_issueMemWriteBackRequest, "imw", desc = "Queue memory write request") {
    queueMemoryWrite(machineID, address, to_memory_controller_latency, cache_entry.DataBlk);
  }

  action(smu_setMRU, "smu", desc = "Set MRU") {
    assert(is_valid(cache_entry));
    cacheMemory.setMRU(cache_entry);
  }

  action(sdm_sendDataFromMem, "sdm", desc = "Send response data to CPU side from mem") {
    peek(memQueue_in, MemoryMsg) {
      enqueue(responseNetwork_out, LLCResponseMsg, 1) {
        assert(is_valid(tbe));
        out_msg.Type        := LLCResponseType:DATA;
        out_msg.LineAddress := in_msg.addr;
        out_msg.Destination.add(tbe.Requestor);
        out_msg.DataBlk     := cache_entry.DataBlk;
        out_msg.MessageSize := MessageSizeType:SingleWordData;
        out_msg.SeqNum      := tbe.SeqNum;
      }
    }
  }

  action(sdc_sendDataFromCache, "sdc", desc = "Send response data to CPU side from cache") {
    peek(requestNetwork_in, LLCRequestMsg) {
      enqueue(responseNetwork_out, LLCResponseMsg, 1) {
        out_msg.Type        := LLCResponseType:DATA;
        out_msg.LineAddress := in_msg.LineAddress;
        out_msg.Destination.add(in_msg.Requestor);
        out_msg.DataBlk     := cache_entry.DataBlk;
        out_msg.MessageSize := MessageSizeType:SingleWordData;
        out_msg.SeqNum      := in_msg.SeqNum;
      }
    }
  }

  // these are special sends just back to the spad (not icache) where only send
  // one word of data b/c don't trace doesn't know which one to use

  action(rsc_remoteStoreFromCache, "rsc", desc = "A remote store to a spad who did not request") {
    peek(requestNetwork_in, LLCRequestMsg) {
      
      // based on vector count get the word in the cache line to send
      // this will always(?) be a linearization
      // put this in the reponse packet so know what to read
      int linOffset := getLinearIdx(in_msg.XDim, in_msg.YDim);
      
      // get the spad to send this to 
      assert(machineIDToMachineType(in_msg.Requestor) == MachineType:Scratchpad);
      NodeID baseId := machineIDToNodeID(in_msg.Requestor);
      int spadIdx := IDToInt(baseId) + linOffset;
      MachineID spad := createMachineID(MachineType:Scratchpad, intToID(spadIdx));
      
      // in case the base address is not aligned to the cache block
      // figure out the block idx for the word this reponse should send
      int wordAddr := addressToInt(in_msg.WordAddress); // cast to int so can subtract
      int lineAddr := addressToInt(in_msg.LineAddress);
      int offsetFromLineAddress := wordAddr - lineAddr + linOffset;
      
      // This functionally sends the whole packet, but the ruby network (garnet)
      // acutally looks at MessageSize to deteremine how many flits are needed
      // to serially send the data over the network.
      // TODO Shouldn't ICACHE response be larger than a singleword? 
      // and shouldn't use this same mechanism??
      enqueue(responseNetwork_out, LLCResponseMsg, 1) {
        out_msg.Type        := LLCResponseType:REDATA;
        out_msg.LineAddress := in_msg.LineAddress;
        out_msg.Destination.add(spad);
        out_msg.DataBlk     := cache_entry.DataBlk;
        out_msg.MessageSize := MessageSizeType:SingleWordData;
        out_msg.SeqNum      := in_msg.SeqNum;
        // this is gem5 only meta-data, in reality would just send the single
        // word, so no need to pick out the element from the whole block
        out_msg.BlkIdx      := offsetFromLineAddress;
      }
    }
  }
  

  action(rsm_remoteStoreFromMem, "rsm", desc = "A remote store to a spad who did not request from mem") {
    peek(memQueue_in, MemoryMsg) {
      // get vec offset
      int linOffset := getLinearIdx(tbe.XDim, tbe.YDim);
      
      // get the spad to send this to 
      assert(machineIDToMachineType(tbe.Requestor) == MachineType:Scratchpad);
      NodeID baseId := machineIDToNodeID(tbe.Requestor);
      int spadIdx := IDToInt(baseId) + linOffset;
      MachineID spad := createMachineID(MachineType:Scratchpad, intToID(spadIdx));
      
      // get offset into cache blk
      int wordAddr := addressToInt(tbe.WordAddress);
      int lineAddr := addressToInt(in_msg.addr);
      int offsetFromLineAddress := wordAddr - lineAddr + linOffset;
      
      enqueue(responseNetwork_out, LLCResponseMsg, 1) {
        assert(is_valid(tbe));
        out_msg.Type        := LLCResponseType:REDATA;
        out_msg.LineAddress := in_msg.addr;
        out_msg.Destination.add(spad);
        out_msg.DataBlk     := cache_entry.DataBlk;
        out_msg.MessageSize := MessageSizeType:SingleWordData;
        out_msg.SeqNum      := tbe.SeqNum;
        out_msg.BlkIdx      := offsetFromLineAddress;
      }
    }
  }

  action(wdc_writeDataToCache, "wdc", desc = "Write data from mem to cache") {
    peek(memQueue_in, MemoryMsg) {
      cache_entry.DataBlk := in_msg.DataBlk;
    }
  }

  action(prq_popRequestQueue, "prq", desc = "Pop a msg from request queue") {
    requestNetwork_in.dequeue(clockEdge());
  }

  action(pmq_popMemResponseQueue, "pmq", desc = "Pop a msg from mem rsp queue") {
    memQueue_in.dequeue(clockEdge());
  }

  action(art_addRequestorToTBE, "art", desc = "Add requestor to TBE") {
    peek(requestNetwork_in, LLCRequestMsg) {
      assert(is_valid(tbe));
      tbe.Requestor := in_msg.Requestor;
      tbe.SeqNum := in_msg.SeqNum;
    }
  }

  action(sdt_saveDataInTBE, "sdt", desc = "Save data from in_msg to TBE") {
    peek(requestNetwork_in, LLCRequestMsg) {
      assert(is_valid(tbe));
      tbe.DataBlk := in_msg.DataBlk;
      tbe.writeMask := in_msg.writeMask;
    }
  }
  
  action(avt_addVecInfoToTBE, "avt", desc = "Add information about vector req to TBE") {
    peek(requestNetwork_in, LLCRequestMsg) {
      assert(is_valid(tbe));
      tbe.XDim := in_msg.XDim;
      tbe.YDim := in_msg.YDim;
      tbe.WordAddress := in_msg.WordAddress;
    }
  }

  action(wdd_writeDirtyDataToCache, "wdd", desc = "Write data to cache") {
    assert(is_valid(cache_entry));
    peek(requestNetwork_in, LLCRequestMsg) {
      cache_entry.DataBlk.copyPartial(in_msg.DataBlk, in_msg.writeMask);
      cache_entry.writeMask.orMask(in_msg.writeMask);
    }
  }

  action(wdt_writeDirtyDataToCacheFromTBE, "wdt", desc = "") {
    assert(is_valid(tbe));
    assert(is_valid(cache_entry));
    cache_entry.DataBlk.copyPartial(tbe.DataBlk, tbe.writeMask);
    cache_entry.writeMask.orMask(tbe.writeMask);
  }

  action(swa_sendWriteAck, "swa", desc = "Send write ack") {
    enqueue(responseNetwork_out, LLCResponseMsg, 1) {
      assert(is_valid(tbe));
      out_msg.Type        := LLCResponseType:ACK;
      out_msg.LineAddress := address;
      out_msg.Destination.add(tbe.Requestor);
      out_msg.MessageSize := MessageSizeType:Response_Control;
      out_msg.SeqNum      := tbe.SeqNum;
    }
  }

  action(dce_deallocateCacheEntry, "dce", desc = "Deallocate a cache entry") {
    if (is_valid(cache_entry)) {
      cacheMemory.deallocate(address);
    }
    unset_cache_entry();
  }

  action(sot_setLLSCOwnerFromTBE, "sot", desc = "Set LL owner") {
    assert(is_valid(tbe));
    assert(is_valid(cache_entry));
    cache_entry.LLSC_owner := tbe.Requestor;
  }

  action(sor_setLLSCOwnerFromRequest, "sor", desc = "Set LL owner from requests") {
    assert(is_valid(cache_entry));
    peek(requestNetwork_in, LLCRequestMsg) {
      cache_entry.LLSC_owner := in_msg.Requestor;
    }
  }

  action(scf_sendFailedSCAck, "scf", desc = "Send Failed SC ACK") {
    enqueue(responseNetwork_out, LLCResponseMsg, 1) {
      assert(is_valid(tbe));
      out_msg.Type        := LLCResponseType:ACK;
      out_msg.LineAddress := address;
      out_msg.Destination.add(tbe.Requestor);
      out_msg.SC_Success  := false;
      out_msg.MessageSize := MessageSizeType:Response_Control;
      out_msg.SeqNum      := tbe.SeqNum;
    }
  }

  action(hsc_handleSCRequest, "hsc", desc = "Handle SC request") {
    assert(is_valid(cache_entry));

    peek(requestNetwork_in, LLCRequestMsg) {
      if (in_msg.Requestor == cache_entry.LLSC_owner) {
        cache_entry.DataBlk.copyPartial(in_msg.DataBlk, in_msg.writeMask);
        cache_entry.writeMask.orMask(in_msg.writeMask);

        // reply requestor
        enqueue(responseNetwork_out, LLCResponseMsg, 1) {
          out_msg.Type        := LLCResponseType:ACK;
          out_msg.LineAddress := address;
          out_msg.Destination.add(in_msg.Requestor);
          out_msg.SC_Success  := true;
          out_msg.MessageSize := MessageSizeType:Response_Control;
          out_msg.SeqNum      := in_msg.SeqNum;
        }

        // set MRU
        cacheMemory.setMRU(cache_entry);
      } else {
        // send Fail ACK
        enqueue(responseNetwork_out, LLCResponseMsg, 1) {
          assert(is_valid(tbe));
          out_msg.Type        := LLCResponseType:ACK;
          out_msg.LineAddress := address;
          out_msg.Destination.add(in_msg.Requestor);
          out_msg.SC_Success  := false;
          out_msg.MessageSize := MessageSizeType:Response_Control;
          out_msg.SeqNum      := in_msg.SeqNum;
        }
      }
    }
  }

  action(dat_doAtomicUpdate, "dat", desc = "Do atomic update") {
    assert(is_valid(tbe));
    assert(is_valid(cache_entry));

    tbe.DataBlk := cache_entry.DataBlk;
    cache_entry.DataBlk.atomicPartial(cache_entry.DataBlk, tbe.writeMask);
    cache_entry.writeMask.orMask(tbe.writeMask);

    // Make a response with old data
    enqueue(responseNetwork_out, LLCResponseMsg, 1) {
      out_msg.Type := LLCResponseType:DATA;
      out_msg.LineAddress := address;
      out_msg.Destination.add(tbe.Requestor);
      out_msg.DataBlk := tbe.DataBlk;
      out_msg.MessageSize := MessageSizeType:SingleWordData;
      out_msg.SeqNum := tbe.SeqNum;
    }
  }

  action(pht_profileHitAccess, "pht", desc = "Profile hit access") {
    ++cacheMemory.demand_hits;
  }

  action(pms_profileMissAccess, "pms", desc = "Profile miss access") {
    ++cacheMemory.demand_misses;
  }

  action(z_stall, "z", desc="stall") {
    // built-in
  }

  action(z_stallAndWait, "zsw", desc = "Stall and wait") {
    stall_and_wait(requestNetwork_in, address);
  }

  action(wua_wakeupAllDependents, "wua", desc = "Wake up all buffers") {
    wakeUpAllBuffers();
  }
  
  // initialize vector request (to 0)
  action(rvm_resetVectorFromMem, "rvm", desc = "Initialize vector req counter") {
    _xCnt := 0;
    _yCnt := 0;
    _vecFromMem := false;
  }
  
  action(rvl_resetVectorFromLLC, "rvl", desc = "Initialize vector req counter") {
    _xCnt := 0;
    _yCnt := 0;
    _vecFromLLC := false;
  }
  
  // handle vector decrement
  action(dvc_decrementVectorCount, "dvc", desc = "Decrement vector count") {
    // enqueue the same packet back on request queue with decremented vec count
    // if no more counts don't put back onto the queue
    peek(requestNetwork_in, LLCRequestMsg) {
      // might need to put in TBE when split across cache line (and you want to do other reqs)
      // store and then restore the count when send req and restore?
      // NOT neccessary because no point to do vector request across a cache line
      // ALSO don't need to worry about banks for this same reason b/c across a cache line
      _xCnt := _xCnt + 1;
      if (_xCnt == in_msg.XDim) {
        _xCnt := 0;
        _yCnt := _yCnt + 1;
      }
      _vecFromLLC := true;
    }
  }
  
  // for missed accesses
  action(dvt_decrementVectorCountTBE, "dvt", desc = "Decrement vector count TBE") {
    _xCnt := _xCnt + 1;
    if (_xCnt == tbe.XDim) {
      _xCnt := 0;
      _yCnt := _yCnt + 1;
    }
    _vecFromMem := true;
  }

  //---------------------------------------------------------------------------
  // Transitions
  //---------------------------------------------------------------------------

  // READ requests

  transition(I, READ, IV) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    avt_addVecInfoToTBE;
    acb_allocateCacheBlock;
    imr_issueMemReadRequest;
    prq_popRequestQueue;
    pms_profileMissAccess;
  }

  transition(V, READ) {
    smu_setMRU;
    sdc_sendDataFromCache;
    rvl_resetVectorFromLLC; // last read (vector or not vector) so reset count
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(M, READ) {
    smu_setMRU;
    sdc_sendDataFromCache;
    rvl_resetVectorFromLLC;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(IV, Memory_Data, V) {
    wdc_writeDataToCache;
    smu_setMRU;
    sdm_sendDataFromMem;
    rvm_resetVectorFromMem;
    dtb_deallocateTBE;
    pmq_popMemResponseQueue;
    wua_wakeupAllDependents;
  }
  
// vector sends, go to vector, only last request is a non-vector one (like original read)
// TODO might want to have real op go first, but then the other port might mode while going
// ... both have pro-cons, but saved by serialization of message in toSPAD outport (presumably serialized)
  transition({V, M}, VREAD) {
    rsc_remoteStoreFromCache;
    dvc_decrementVectorCount;
  }
  
  /*transition(M, VREAD) {
    sdc_sendDataFromCache;
    dvc_decrementVectorCount;
  }*/
  
  transition(IV, VMemory_Data) {
    rsm_remoteStoreFromMem;
    dvt_decrementVectorCountTBE;
  }

  transition({IV, MI, IM, IV_LL, IA}, READ) {
    z_stallAndWait;
  }

  // LL requests

  transition(I, LL, IV_LL) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    acb_allocateCacheBlock;
    imr_issueMemReadRequest;
    prq_popRequestQueue;
    pms_profileMissAccess;
  }

  transition(V, LL) {
    smu_setMRU;
    sor_setLLSCOwnerFromRequest;
    sdc_sendDataFromCache;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(M, LL) {
    smu_setMRU;
    sor_setLLSCOwnerFromRequest;
    sdc_sendDataFromCache;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(IV_LL, Memory_Data, V) {
    wdc_writeDataToCache;
    sot_setLLSCOwnerFromTBE;
    smu_setMRU;
    sdm_sendDataFromMem;
    dtb_deallocateTBE;
    pmq_popMemResponseQueue;
    wua_wakeupAllDependents;
  }

  transition({IV, MI, IM, IV_LL, IA}, LL) {
    z_stallAndWait;
  }

  // WRITE requests

  transition(V, WRITE, M) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    smu_setMRU;
    wdd_writeDirtyDataToCache;
    swa_sendWriteAck;
    dtb_deallocateTBE;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(M, WRITE) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    smu_setMRU;
    wdd_writeDirtyDataToCache;
    swa_sendWriteAck;
    dtb_deallocateTBE;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(I, WRITE, IM) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    sdt_saveDataInTBE;
    acb_allocateCacheBlock;
    imr_issueMemReadRequest;
    prq_popRequestQueue;
    pms_profileMissAccess;
  }

  transition(IM, Memory_Data, M) {
    wdc_writeDataToCache;
    wdt_writeDirtyDataToCacheFromTBE;
    swa_sendWriteAck;
    smu_setMRU;
    dtb_deallocateTBE;
    pmq_popMemResponseQueue;
    wua_wakeupAllDependents;
  }

  transition({IV, MI, IM, IV_LL, IA}, WRITE) {
    z_stallAndWait;
  }

  // SC requests

  transition(I, SC) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    scf_sendFailedSCAck;
    dtb_deallocateTBE;
    prq_popRequestQueue;
    pms_profileMissAccess;
  }

  transition(V, SC, M) {
    hsc_handleSCRequest;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(M, SC) {
    hsc_handleSCRequest;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition({IV, MI, IM, IV_LL, IA}, SC) {
    z_stallAndWait;
  }

  // ATOMIC requests

  transition(V, ATOMIC, M) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    sdt_saveDataInTBE;
    smu_setMRU;
    dat_doAtomicUpdate;
    dtb_deallocateTBE;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(M, ATOMIC) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    sdt_saveDataInTBE;
    smu_setMRU;
    dat_doAtomicUpdate;
    dtb_deallocateTBE;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(I, ATOMIC, IA) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    sdt_saveDataInTBE;
    acb_allocateCacheBlock;
    imr_issueMemReadRequest;
    prq_popRequestQueue;
    pms_profileMissAccess;
  }

  transition(IA, Memory_Data, M) {
    wdc_writeDataToCache;
    dat_doAtomicUpdate;
    smu_setMRU;
    dtb_deallocateTBE;
    pmq_popMemResponseQueue;
    wua_wakeupAllDependents;
  }

  transition({IV, MI, IM, IV_LL, IA}, ATOMIC) {
    z_stallAndWait;
  }

  // REPL

  transition({V, I}, Repl, I) {
    dce_deallocateCacheEntry;
  }

  transition(M, Repl, MI) {
    atb_allocateTBE;
    imw_issueMemWriteBackRequest;
    dce_deallocateCacheEntry;
  }

  transition(MI, Memory_Ack, I) {
    dtb_deallocateTBE;
    pmq_popMemResponseQueue;
    wua_wakeupAllDependents;
  }

  transition({IV, MI, IM, IV_LL, IA}, Repl) {
    z_stallAndWait;
  }
}
