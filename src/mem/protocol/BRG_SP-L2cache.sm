//-----------------------------------------------------------------------------
// SP_LLC-cache.sm
//-----------------------------------------------------------------------------
// This models LLC cache
//
// Author: Tuan Ta
// Date  : 19/07/03

machine(MachineType:L2Cache, "SP LLC cache")
    : CacheMemory* cacheMemory;
      Cycles cache_resp_latency := 12;
      Cycles to_memory_controller_latency := 1;

      MessageBuffer* requestToLLC,    network = "From", virtual_network = "1", vnet_type = "request";
      MessageBuffer* responseFromLLC, network = "To",   virtual_network = "0", vnet_type = "response";
      MessageBuffer* responseFromMemory;

      int meshDimX := 2;
      int meshDimY := 2;
      
{
  //---------------------------------------------------------------------------
  // Global state... registers in this mem controller
  //---------------------------------------------------------------------------
  
  // counters in the mem controller
  //int _xCnt := 0;
  //int _yCnt := 0;

  int _vecCnt := 0;
      
  // prevent both inports from starting vector op while other is in progress
  // TODO this prob should also prevent multiple vector ops from happening in the same
  // cycle. Currenlty allowing (just like for cache lines) where send all in 1 cycle
  // and have the network serialize it.
  bool _vecFromMem := false;
  bool _vecFromLLC := false;
  
  //---------------------------------------------------------------------------
  // States
  //---------------------------------------------------------------------------

  state_declaration(State, desc = "", default = "L2Cache_State_I") {
    I,     AccessPermission:Invalid,     desc = "Not present/invalid";
    IV,    AccessPermission:Busy,        desc = "Waiting for data";
    IM,    AccessPermission:Busy,        desc = "Waiting for data";
    V,     AccessPermission:Read_Write,  desc = "Valid & clean";
    M,     AccessPermission:Read_Write,  desc = "Valid & dirty";
    MI,    AccessPermission:Busy,        desc = "Waiting for writeback ACK";
    IV_LL, AccessPermission:Busy,        desc = "Waiting for data (LL request)";
    IA,    AccessPermission:Busy,        desc = "Waiting for data (ATOMIC request)";
  }

  //---------------------------------------------------------------------------
  // Events
  //---------------------------------------------------------------------------

  enumeration(Event, desc = "Cache events") {
    // from scratchpads
    READ,   desc = "A READ request arrives";
    VREAD0, desc = "The initial vec read";
    VREAD1, desc = "The middle vec read(s)";
    VREAD2, desc = "The last vec read";
    SPLOAD, desc = "Store to spad instead of CPU";
    WRITE,  desc = "A WRITE request arrives";
    LL,     desc = "A LL request arrives";
    SC,     desc = "A SC request arrives";
    ATOMIC, desc = "An ATOMIC request arrives";
    Repl,   desc = "Replacement";
    STALL,  desc = "Just stall for the cycle";

    // from memory
    Memory_Data,  desc = "Fetched data from memory arrives";
    VData0,       desc = "Fetched data from memory arrives and do vec op"; // kinda hacky
    VData1,       desc = "Fetched data from memory arrives and do vec op";
    VData2,       desc = "Fetched data from memory arrives and do vec op";
    SP_Mem_Data,  desc = "Fetched data from memory arrives and single sp load";
    Memory_Ack,   desc = "Writeback Ack from memory arrives";
  }

  //---------------------------------------------------------------------------
  // Cache entry
  //---------------------------------------------------------------------------

  structure(Entry, desc = "...", interface = "AbstractCacheEntry") {
    State CacheState,     desc = "Cache state";
    DataBlock DataBlk,    desc = "Data in the block";
    WriteMask writeMask,  desc = "Dirty byte mask";
    MachineID LLSC_owner, desc = "Owner of LLSC lock";
  }

  //---------------------------------------------------------------------------
  // TBE entry
  //---------------------------------------------------------------------------

  // Data stored from a packet once taken out of RequestBuf. Needed to finish req when mem resp arrives
  structure(TBE, desc = "...") {
    State     TBEState,   desc = "Transient state";
    DataBlock DataBlk,    desc = "Data for the block";
    WriteMask writeMask,  desc = "Dirty byte mask";
    MachineID Requestor,  desc = "Requestor's ID";
    int       SeqNum,     desc = "Sequence number";
    int       XDim,       desc = "X dimension to access for";
    int       YDim,       desc = "Y dimension to access for";
    int       VecOffset,  desc = "Offset to the vector group due to decoupled access (1bit?)";
    bool      FromDA,     desc = "Is access from a decoupled access core";
    Addr      WordAddress,desc = "Word address of element request";
    Addr      PrefetchAddress, desc = "Prefetch address, same wire as datablk";
    int       Epoch,      desc = "Epoch of the requester";
    LLCRequestType InType, desc = "Keep track of input event to know what to do when get mem";
  }

  structure(TBETable, external = "yes") {
    TBE lookup(Addr);
    void allocate(Addr);
    void deallocate(Addr);
    bool isPresent(Addr);
    bool areNSlotsAvailable(int, Tick);
  }

  //---------------------------------------------------------------------------
  // Structures
  //---------------------------------------------------------------------------

  TBETable TBEs, template="<L2Cache_TBE>", constructor="m_number_of_TBEs";

  //---------------------------------------------------------------------------
  // Prototypes
  //---------------------------------------------------------------------------

  Tick clockEdge();
  Cycles ticksToCycles(Tick t);
  void set_cache_entry(AbstractCacheEntry a);
  void unset_cache_entry();
  void set_tbe(TBE b);
  void unset_tbe();
  void wakeUpAllBuffers();

  //---------------------------------------------------------------------------
  // Functions
  //---------------------------------------------------------------------------

  Entry getCacheEntry(Addr address), return_by_pointer="yes" {
    return static_cast(Entry, "pointer", cacheMemory.lookup(address));
  }

  State getState(TBE tbe, Entry cache_entry, Addr addr) {
    if (is_valid(tbe)) {
      return tbe.TBEState;
    } else if (is_valid(cache_entry)) {
      return cache_entry.CacheState;
    } else {
      return State:I;
    }
  }

  void setState(TBE tbe, Entry cache_entry, Addr addr, State state) {
    if (is_valid(tbe)) {
      tbe.TBEState := state;
    }

    if (is_valid(cache_entry)) {
      cache_entry.CacheState := state;
    }
  }

  AccessPermission getAccessPermission(Addr addr) {
    TBE tbe := TBEs[addr];

    if (is_valid(tbe)) {
      return L2Cache_State_to_permission(tbe.TBEState);
    }

    Entry cache_entry := getCacheEntry(addr);

    if (is_valid(cache_entry)) {
      return L2Cache_State_to_permission(cache_entry.CacheState);
    }

    return AccessPermission:NotPresent;
  }

  void setAccessPermission(Entry cache_entry, Addr addr, State state) {
    if (is_valid(cache_entry)) {
      cache_entry.changePermission(L2Cache_State_to_permission(state));
    }
  }

  bool functionalRead(Addr addr, Packet *pkt) {
    TBE tbe := TBEs[addr];
    Entry cache_entry := getCacheEntry(addr);

    if (is_valid(tbe)) {
      return testAndRead(addr, tbe.DataBlk, pkt);
    } else if (is_valid(cache_entry)) {
      return testAndRead(addr, getCacheEntry(addr).DataBlk, pkt);
    } else {
      functionalMemoryRead(pkt);
      return true;
    }
  }

  int functionalWrite(Addr addr, Packet *pkt) {
    int num_functional_writes := 0;
    TBE tbe := TBEs[addr];
    Entry cache_entry := getCacheEntry(addr);

    if (is_valid(tbe)) {
      num_functional_writes := num_functional_writes +
                        testAndWrite(addr, tbe.DataBlk, pkt);
    } else if (is_valid(cache_entry)) {
      num_functional_writes := num_functional_writes +
                        testAndWrite(addr, getCacheEntry(addr).DataBlk, pkt);
    } else if (version == intToID(0)) {
      // only one L2 bank needs to do the functional write to memory, so let
      // the first L2 do it.
      num_functional_writes := num_functional_writes +
                        functionalMemoryWrite(pkt);
    }

    return num_functional_writes;
  }

  bool isCacheEntryPresent(Addr addr) {
    return cacheMemory.isTagPresent(addr);
  }
  
  int getLinearIdx(int xDim, int yDim) {
    return _vecCnt;
  }

  int mod(int a, int b) {
    return a - (a / b) * b;
  }

  // can linearize with respect to x or y and get diff sends
  // currently doing by x first
  int getCoreIdx(int coreIdx, int coreOffset, int vecDimX, int vecDimY, bool fromDA) {
    // get the starting core idx
    // substract offset if originating from master??
    int startingCoreIdx := coreIdx;
    if (fromDA == false) {
      startingCoreIdx := startingCoreIdx - coreOffset;
    }

    // add flat offset to vec cnt
    int vecFlat := _vecCnt + coreOffset;

    // get the x y of the current vec count
    int vecX := mod(vecFlat, vecDimX);
    int vecY := vecFlat / vecDimX;

    // linearize vec count with respect to mesh
    int meshVecFlat := vecX + vecY * meshDimX;

    // linearize on mesh cores
    int respIdx := startingCoreIdx + meshVecFlat;
    return respIdx;
  }

  bool isFirstLoadOfVec() {
    // return (_xCnt == 0) && (_yCnt == 0);
    return _vecCnt == 0;
  }

  bool isLastLoadOfVec(int xDim, int yDim) {
    // return (_xCnt == xDim - 1) && (_yCnt == yDim - 1);
    return (_vecCnt == (xDim * yDim - 1));
  }

  void increaseVecCount(int xDim) {
    // _xCnt := _xCnt + 1;
    // if (_xCnt == xDim) {
    //   _xCnt := 0;
    //   _yCnt := _yCnt + 1;
    // }
    _vecCnt := _vecCnt + 1;
  }

  void resetVecCntr() {
    //_xCnt := 0;
    //_yCnt := 0;
    _vecCnt := 0;
  }
  
  bool isVector(int xDim, int yDim) {
    return (xDim > 1 && yDim > 1);
  }

  //---------------------------------------------------------------------------
  // Network ports
  //---------------------------------------------------------------------------

  // Responses to CPU side
  out_port(responseNetwork_out, LLCResponseMsg, responseFromLLC);

  // Requests coming from CPU side
  in_port(requestNetwork_in, LLCRequestMsg, requestToLLC) {
    if (requestNetwork_in.isReady(clockEdge())) {
      peek(requestNetwork_in, LLCRequestMsg) {

        //Addr LineAddress := makeLineAddress(in_msg.WordAddress);
        //assert(LineAddress == in_msg.LineAddress); why isn't this the same!!
        Addr LineAddress := in_msg.LineAddress;
        
        // sanity check
        assert(in_msg.XDim > 0 && in_msg.YDim > 0);
        
        Entry cache_entry := getCacheEntry(LineAddress);
        
        DPRINTF(RubySlicc, "%s arrived\n", in_msg);
        //DPRINTF(Mesh, "slots available %d\n", TBEs.areNSlotsAvailable(1, clockEdge()));
        if (TBEs.areNSlotsAvailable(1, clockEdge())) {
          if (is_invalid(cache_entry) &&
              cacheMemory.cacheAvail(LineAddress) == false) {
            // No available cache line for this address -> trigger cache
            // replacement
            Addr victim := cacheMemory.cacheProbe(LineAddress);
            trigger(Event:Repl, victim, getCacheEntry(victim), TBEs.lookup(victim));
          } else {
            
            // There's an available slot
            TBE tbe := TBEs[LineAddress];
          
            // check if vector or not (TODO should prob check RequestType rather than vlen)
            // TODO on vector, taking multiple 'transitions' to send
            // potentially blocking other things like mem req from happening for
            // a few cycles. Not really sure how faithfully any of this is modeled
            // just going to do the easiest to implement thing, which may end up
            // being worse than the baseline because blocking mem reqs more due to
            // multiple reqs.... 
            // See transitions_per_cycle in Controller.py
            if (in_msg.Type == LLCRequestType:SPLOAD) {
              if (isVector(in_msg.XDim, in_msg.YDim)) {
                //DPRINTF(Mesh, "req (%d %d) %d %d\n", _xCnt, _yCnt, _vecFromMem, getState(tbe, cache_entry, LineAddress));
                if (!_vecFromMem) {
                  if (isFirstLoadOfVec()) { // TODO need to support non-vec sp load, need special req type
                    trigger(Event:VREAD0, LineAddress, cache_entry, tbe);
                  }
                  else if (!isLastLoadOfVec(in_msg.XDim, in_msg.YDim)) {
                    trigger(Event:VREAD1, LineAddress, cache_entry, tbe);
                  }
                  else {
                    trigger(Event:VREAD2, LineAddress, cache_entry, tbe);
                  }
                } else {
                  DPRINTF(Mesh, "[[WARNING]] stalling req pkt %#x\n", in_msg.WordAddress);
                  // stall bro
                  trigger(Event:STALL, LineAddress, cache_entry, tbe);
                }
              } else { // single remote store
                trigger(Event:SPLOAD, LineAddress, cache_entry, tbe);
              }
            } else if (in_msg.Type == LLCRequestType:READ) {
              trigger(Event:READ, LineAddress, cache_entry, tbe);
            } else if (in_msg.Type == LLCRequestType:WRITE) {
              trigger(Event:WRITE, LineAddress, cache_entry, tbe);
            } else if (in_msg.Type == LLCRequestType:LL) {
              trigger(Event:LL, LineAddress, cache_entry, tbe);
            } else if (in_msg.Type == LLCRequestType:SC) {
              trigger(Event:SC, LineAddress, cache_entry, tbe);
            } else if (in_msg.Type == LLCRequestType:ATOMIC) {
              trigger(Event:ATOMIC, LineAddress, cache_entry, tbe);
            } else {
              error("Invalid message");
            }
          }
        } else {
          TBE tbe := TBEs[LineAddress];
          trigger(Event:STALL, LineAddress, cache_entry, tbe);
        }
      }
    }
  }

  // Responses from memory controller
  in_port(memQueue_in, MemoryMsg, responseFromMemory) {
    if (memQueue_in.isReady(clockEdge())) {
      peek(memQueue_in, MemoryMsg, block_on = "addr") {
        TBE tbe := TBEs.lookup(in_msg.addr);
        assert(is_valid(tbe));

        Entry cache_entry := getCacheEntry(in_msg.addr);

        if (tbe.InType == LLCRequestType:SPLOAD) {
          if (isVector(tbe.XDim, tbe.YDim)) {
            if (!_vecFromLLC) {
              assert(is_valid(cache_entry));
              //DPRINTF(Mesh, "req (%d,%d) %d %d\n", _xCnt, _yCnt, _vecFromLLC, getState(tbe, cache_entry, in_msg.addr));
              if (isFirstLoadOfVec()) {
                trigger(Event:VData0, in_msg.addr, cache_entry, tbe);
              }
              else if (!isLastLoadOfVec(tbe.XDim, tbe.YDim)) {
                trigger(Event:VData1, in_msg.addr, cache_entry, tbe);
              }
              else {
                trigger(Event:VData2, in_msg.addr, cache_entry, tbe);
              }
            }
            else {
              // stall bro
              trigger(Event:STALL, in_msg.addr, cache_entry, tbe);
            }
          } else {
            // single spread
            trigger(Event:SP_Mem_Data, in_msg.addr, cache_entry, tbe);
          }
        } else if (in_msg.Type == MemoryRequestType:MEMORY_READ) {
          assert(is_valid(cache_entry));
          trigger(Event:Memory_Data, in_msg.addr, cache_entry, tbe);
        } else if (in_msg.Type == MemoryRequestType:MEMORY_WB) {
          trigger(Event:Memory_Ack, in_msg.addr, cache_entry, tbe);
        } else {
          error("Invalid message");
        }
      }
    }
  }

  //---------------------------------------------------------------------------
  // Actions
  //---------------------------------------------------------------------------

  action(atb_allocateTBE, "atb", desc = "Allocate TBE") {
    TBEs.allocate(address);
    set_tbe(TBEs[address]);
  }

  action(dtb_deallocateTBE, "dtb", desc = "Deallocate TBE") {
    TBEs.deallocate(address);
    unset_tbe();
  }

  action(acb_allocateCacheBlock, "acb", desc = "Allocate cache block") {
    if (is_valid(cache_entry) == false) {
      set_cache_entry(cacheMemory.allocate(address, new Entry));
      cache_entry.LLSC_owner := createMachineID(MachineType:NULL, intToID(0));
    }
  }

  action(imr_issueMemReadRequest, "imr", desc = "Queue memory read request") {
    peek(requestNetwork_in, LLCRequestMsg) {
      queueMemoryRead(in_msg.Requestor, address, to_memory_controller_latency);
    }
  }

  action(imw_issueMemWriteBackRequest, "imw", desc = "Queue memory write request") {
    queueMemoryWrite(machineID, address, to_memory_controller_latency, cache_entry.DataBlk);
  }

  action(smu_setMRU, "smu", desc = "Set MRU") {
    assert(is_valid(cache_entry));
    cacheMemory.setMRU(cache_entry);
  }

  action(sdm_sendDataFromMem, "sdm", desc = "Send response data to CPU side from mem") {
    peek(memQueue_in, MemoryMsg) {
      enqueue(responseNetwork_out, LLCResponseMsg, 1) {
        assert(is_valid(tbe));
        out_msg.Type        := LLCResponseType:DATA;
        out_msg.LineAddress := in_msg.addr;
        out_msg.Destination.add(tbe.Requestor);
        out_msg.DataBlk     := cache_entry.DataBlk;
        out_msg.MessageSize := MessageSizeType:SingleWordData;
        out_msg.SeqNum      := tbe.SeqNum;
      }
    }
  }

  action(sdc_sendDataFromCache, "sdc", desc = "Send response data to CPU side from cache") {
    peek(requestNetwork_in, LLCRequestMsg) {
      if (in_msg.XDim > 1) {
        DPRINTF(Mesh, "resp to addr %#x\n", in_msg.LineAddress);
      }
      
      enqueue(responseNetwork_out, LLCResponseMsg, 1) {
        out_msg.Type        := LLCResponseType:DATA;
        out_msg.LineAddress := in_msg.LineAddress;
        out_msg.Destination.add(in_msg.Requestor);
        out_msg.DataBlk     := cache_entry.DataBlk;
        out_msg.MessageSize := MessageSizeType:SingleWordData;
        out_msg.SeqNum      := in_msg.SeqNum;
      }
    }
  }

  // these are special sends just back to the spad (not icache) where only send
  // one word of data b/c don't trace doesn't know which one to use

  action(rsc_remoteStoreFromCache, "rsc", desc = "A remote store to a spad who did not request") {
    peek(requestNetwork_in, LLCRequestMsg) {
      
      // based on vector count get the word in the cache line to send
      // this will always(?) be a linearization
      // put this in the reponse packet so know what to read
      int linOffset := getLinearIdx(in_msg.XDim, in_msg.YDim);
      if (!isVector(in_msg.XDim, in_msg.YDim)) {
        assert(linOffset == 0);
      }
      
      // get the spad to send this to 
      assert(machineIDToMachineType(in_msg.Requestor) == MachineType:Scratchpad);
      NodeID baseId := machineIDToNodeID(in_msg.Requestor);
      // int spadIdx := IDToInt(baseId) + linOffset;
      int coreIdx := IDToInt(baseId);
      int spadIdx := getCoreIdx(coreIdx, in_msg.VecOffset, in_msg.XDim, in_msg.YDim, in_msg.FromDA);
      int coreOffset := spadIdx - coreIdx;
      MachineID spad := createMachineID(MachineType:Scratchpad, intToID(spadIdx));
      
      // in case the base address is not aligned to the cache block
      // figure out the block idx for the word this reponse should send
      int wordAddr := addressToInt(in_msg.WordAddress); // cast to int so can subtract
      int lineAddr := addressToInt(in_msg.LineAddress);
      
      // get offset IN WORDS, need to divide by word size
      int wordOffset := ((wordAddr - lineAddr) / 4) + linOffset;
      
      //DPRINTF(Mesh, "offset %d line %d addr %d\n", wordOffset, lineAddr, wordAddr);
      
      // because this mimics a remote store, the return address should be
      // the storage address in the spad
      Addr spadAddr := intToAddress(addressToInt(in_msg.PrefetchAddress) + (coreOffset << 12)); //intToAddress(268435472 + (spadIdx << 12));
      
      DPRINTF(Mesh, "remote store to spad %d from spad %d @ addr %#x from mem %#x lineaddr %#x offset %d epoch %d\n", 
        spadIdx, coreIdx, spadAddr, in_msg.WordAddress, in_msg.LineAddress, wordOffset, in_msg.Epoch);
      
      // if vector then send REVDATA, otherwise REDATA
      // TODO maybe should just be seperate
      LLCResponseType respType;
      if (isVector(in_msg.XDim, in_msg.YDim)) {
        respType := LLCResponseType:REVDATA;
      }
      else {
        respType := LLCResponseType:REDATA;
      }
      
      // This functionally sends the whole packet, but the ruby network (garnet)
      // acutally looks at MessageSize to deteremine how many flits are needed
      // to serially send the data over the network.
      // TODO Shouldn't ICACHE response be larger than a singleword? 
      // and shouldn't use this same mechanism??
      enqueue(responseNetwork_out, LLCResponseMsg, 1) {
        out_msg.Type        := respType;
        out_msg.LineAddress := spadAddr;
        out_msg.Destination.add(spad);
        out_msg.DataBlk     := cache_entry.DataBlk;
        out_msg.MessageSize := MessageSizeType:SingleWordData;
        out_msg.SeqNum      := in_msg.SeqNum;
        // this is gem5 only meta-data, in reality would just send the single
        // word, so no need to pick out the element from the whole block
        out_msg.BlkIdx      := wordOffset;
        out_msg.Epoch       := in_msg.Epoch;
      }
    }
  }
  

  action(rsm_remoteStoreFromMem, "rsm", desc = "A remote store to a spad who did not request from mem") {
    peek(memQueue_in, MemoryMsg) {
      // get vec offset
      int linOffset := getLinearIdx(tbe.XDim, tbe.YDim);
      
      // get the spad to send this to 
      assert(machineIDToMachineType(tbe.Requestor) == MachineType:Scratchpad);
      NodeID baseId := machineIDToNodeID(tbe.Requestor);
      int coreIdx := IDToInt(baseId);
      int spadIdx := getCoreIdx(coreIdx, tbe.VecOffset, tbe.XDim, tbe.YDim, tbe.FromDA);
      int coreOffset := spadIdx - coreIdx;
      MachineID spad := createMachineID(MachineType:Scratchpad, intToID(spadIdx));
      
      // get offset into cache blk
      int wordAddr := addressToInt(tbe.WordAddress);
      int lineAddr := addressToInt(in_msg.addr);
      // get offset IN WORDS, need to divide by word size
      int wordOffset := ((wordAddr - lineAddr) / 4) + linOffset;
      
      //Addr spadAddr := intToAddress(268435472 + (spadIdx << 12));
      Addr spadAddr := intToAddress(addressToInt(tbe.PrefetchAddress) + (coreOffset << 12));
      
      // if vector then send REVDATA, otherwise REDATA
      LLCResponseType respType;
      if (isVector(tbe.XDim, tbe.YDim)) {
        respType := LLCResponseType:REVDATA;
      }
      else {
        respType := LLCResponseType:REDATA;
      }
      
      DPRINTF(Mesh, "remote store to spad %d from spad %d @ addr %#x from mem %#x prefetch %#x offset %d epoch %d\n", 
        spadIdx, coreIdx, spadAddr, tbe.WordAddress, tbe.PrefetchAddress, wordOffset, tbe.Epoch);
      
      enqueue(responseNetwork_out, LLCResponseMsg, 1) {
        assert(is_valid(tbe));
        out_msg.Type        := respType;
        out_msg.LineAddress := spadAddr;
        out_msg.Destination.add(spad);
        out_msg.DataBlk     := cache_entry.DataBlk;
        out_msg.MessageSize := MessageSizeType:SingleWordData;
        out_msg.SeqNum      := tbe.SeqNum;
        out_msg.BlkIdx      := wordOffset;
        out_msg.Epoch       := tbe.Epoch;
      }
    }
  }
  
  // acknoweldge a prefetch was send (was a hit
  /*action(pah_prefetchAckHit, "pah", desc = "Send prefetch ack on hit") {
    peek(requestNetwork_in, LLCRequestMsg) {
      enqueue(responseNetwork_out, LLCResponseMsg, 1) {
        out_msg.Type        := LLCResponseType:ACK;
        out_msg.LineAddress := address;
        out_msg.Destination.add(in_msg.Requestor);
        out_msg.MessageSize := MessageSizeType:Response_Control;
        out_msg.SeqNum      := in_msg.SeqNum;
      }
    }
  }
  
  action(pam_prefetchAckMiss, "pam", desc = "Send prefetch ack on miss") {
    enqueue(responseNetwork_out, LLCResponseMsg, 1) {
      assert(is_valid(tbe));
      out_msg.Type        := LLCResponseType:ACK;
      out_msg.LineAddress := address;
      out_msg.Destination.add(tbe.Requestor);
      out_msg.MessageSize := MessageSizeType:Response_Control;
      out_msg.SeqNum      := tbe.SeqNum;
    }
  }*/

  action(wdc_writeDataToCache, "wdc", desc = "Write data from mem to cache") {
    peek(memQueue_in, MemoryMsg) {
      cache_entry.DataBlk := in_msg.DataBlk;
    }
  }

  action(prq_popRequestQueue, "prq", desc = "Pop a msg from request queue") {
    requestNetwork_in.dequeue(clockEdge());
  }

  action(pmq_popMemResponseQueue, "pmq", desc = "Pop a msg from mem rsp queue") {
    memQueue_in.dequeue(clockEdge());
  }

  action(art_addRequestorToTBE, "art", desc = "Add requestor to TBE") {
    peek(requestNetwork_in, LLCRequestMsg) {
      assert(is_valid(tbe));
      tbe.Requestor := in_msg.Requestor;
      tbe.SeqNum := in_msg.SeqNum;
    }
  }

  action(sdt_saveDataInTBE, "sdt", desc = "Save data from in_msg to TBE") {
    peek(requestNetwork_in, LLCRequestMsg) {
      assert(is_valid(tbe));
      tbe.DataBlk := in_msg.DataBlk;
      tbe.writeMask := in_msg.writeMask;
    }
  }
  
  action(avt_addVecInfoToTBE, "avt", desc = "Add information about vector req to TBE") {
    peek(requestNetwork_in, LLCRequestMsg) {
      assert(is_valid(tbe));
      tbe.XDim := in_msg.XDim;
      tbe.YDim := in_msg.YDim;
      tbe.VecOffset := in_msg.VecOffset;
      tbe.FromDA := in_msg.FromDA;
      tbe.WordAddress := in_msg.WordAddress;
      tbe.PrefetchAddress := in_msg.PrefetchAddress;
      tbe.Epoch := in_msg.Epoch;
      tbe.InType := in_msg.Type;
    }
  }

  action(wdd_writeDirtyDataToCache, "wdd", desc = "Write data to cache") {
    assert(is_valid(cache_entry));
    peek(requestNetwork_in, LLCRequestMsg) {
      cache_entry.DataBlk.copyPartial(in_msg.DataBlk, in_msg.writeMask);
      cache_entry.writeMask.orMask(in_msg.writeMask);
    }
  }

  action(wdt_writeDirtyDataToCacheFromTBE, "wdt", desc = "") {
    assert(is_valid(tbe));
    assert(is_valid(cache_entry));
    cache_entry.DataBlk.copyPartial(tbe.DataBlk, tbe.writeMask);
    cache_entry.writeMask.orMask(tbe.writeMask);
  }

  action(swa_sendWriteAck, "swa", desc = "Send write ack") {
    enqueue(responseNetwork_out, LLCResponseMsg, 1) {
      assert(is_valid(tbe));
      out_msg.Type        := LLCResponseType:ACK;
      out_msg.LineAddress := address;
      out_msg.Destination.add(tbe.Requestor);
      out_msg.MessageSize := MessageSizeType:Response_Control;
      out_msg.SeqNum      := tbe.SeqNum;
    }
  }

  action(dce_deallocateCacheEntry, "dce", desc = "Deallocate a cache entry") {
    if (is_valid(cache_entry)) {
      cacheMemory.deallocate(address);
    }
    unset_cache_entry();
  }

  action(sot_setLLSCOwnerFromTBE, "sot", desc = "Set LL owner") {
    assert(is_valid(tbe));
    assert(is_valid(cache_entry));
    cache_entry.LLSC_owner := tbe.Requestor;
  }

  action(sor_setLLSCOwnerFromRequest, "sor", desc = "Set LL owner from requests") {
    assert(is_valid(cache_entry));
    peek(requestNetwork_in, LLCRequestMsg) {
      cache_entry.LLSC_owner := in_msg.Requestor;
    }
  }

  action(scf_sendFailedSCAck, "scf", desc = "Send Failed SC ACK") {
    enqueue(responseNetwork_out, LLCResponseMsg, 1) {
      assert(is_valid(tbe));
      out_msg.Type        := LLCResponseType:ACK;
      out_msg.LineAddress := address;
      out_msg.Destination.add(tbe.Requestor);
      out_msg.SC_Success  := false;
      out_msg.MessageSize := MessageSizeType:Response_Control;
      out_msg.SeqNum      := tbe.SeqNum;
    }
  }

  action(hsc_handleSCRequest, "hsc", desc = "Handle SC request") {
    assert(is_valid(cache_entry));

    peek(requestNetwork_in, LLCRequestMsg) {
      if (in_msg.Requestor == cache_entry.LLSC_owner) {
        cache_entry.DataBlk.copyPartial(in_msg.DataBlk, in_msg.writeMask);
        cache_entry.writeMask.orMask(in_msg.writeMask);

        // reply requestor
        enqueue(responseNetwork_out, LLCResponseMsg, 1) {
          out_msg.Type        := LLCResponseType:ACK;
          out_msg.LineAddress := address;
          out_msg.Destination.add(in_msg.Requestor);
          out_msg.SC_Success  := true;
          out_msg.MessageSize := MessageSizeType:Response_Control;
          out_msg.SeqNum      := in_msg.SeqNum;
        }

        // set MRU
        cacheMemory.setMRU(cache_entry);
      } else {
        // send Fail ACK
        enqueue(responseNetwork_out, LLCResponseMsg, 1) {
          assert(is_valid(tbe));
          out_msg.Type        := LLCResponseType:ACK;
          out_msg.LineAddress := address;
          out_msg.Destination.add(in_msg.Requestor);
          out_msg.SC_Success  := false;
          out_msg.MessageSize := MessageSizeType:Response_Control;
          out_msg.SeqNum      := in_msg.SeqNum;
        }
      }
    }
  }

  action(dat_doAtomicUpdate, "dat", desc = "Do atomic update") {
    assert(is_valid(tbe));
    assert(is_valid(cache_entry));

    tbe.DataBlk := cache_entry.DataBlk;
    cache_entry.DataBlk.atomicPartial(cache_entry.DataBlk, tbe.writeMask);
    cache_entry.writeMask.orMask(tbe.writeMask);

    // Make a response with old data
    enqueue(responseNetwork_out, LLCResponseMsg, 1) {
      out_msg.Type := LLCResponseType:DATA;
      out_msg.LineAddress := address;
      out_msg.Destination.add(tbe.Requestor);
      out_msg.DataBlk := tbe.DataBlk;
      out_msg.MessageSize := MessageSizeType:SingleWordData;
      out_msg.SeqNum := tbe.SeqNum;
    }
  }

  action(pht_profileHitAccess, "pht", desc = "Profile hit access") {
    ++cacheMemory.demand_hits;
  }

  action(pms_profileMissAccess, "pms", desc = "Profile miss access") {
    ++cacheMemory.demand_misses;
  }

  action(z_stall, "z", desc="stall") {
    // built-in
  }

  action(z_stallAndWait, "zsw", desc = "Stall and wait") {
    stall_and_wait(requestNetwork_in, address);
  }

  action(wua_wakeupAllDependents, "wua", desc = "Wake up all buffers") {
    wakeUpAllBuffers();
  }
  
  // initialize vector request (to 0)
  action(rvm_resetVectorFromMem, "rvm", desc = "Initialize vector req counter") {
    resetVecCntr();
    _vecFromMem := false;
  }
  
  action(rvl_resetVectorFromLLC, "rvl", desc = "Initialize vector req counter") {
    resetVecCntr();
    _vecFromLLC := false;
  }
  
  // handle vector decrement
  action(ivc_incVectorCount, "ivc", desc = "Increment vector count") {
    // enqueue the same packet back on request queue with decremented vec count
    // if no more counts don't put back onto the queue
    peek(requestNetwork_in, LLCRequestMsg) {
      // might need to put in TBE when split across cache line (and you want to do other reqs)
      // store and then restore the count when send req and restore?
      // NOT neccessary because no point to do vector request across a cache line
      // ALSO don't need to worry about banks for this same reason b/c across a cache line
      increaseVecCount(in_msg.XDim);
      _vecFromLLC := true;
    }
  }
  
  // for missed accesses
  action(ivt_incVectorCountTBE, "ivt", desc = "Increment vector count TBE") {
    increaseVecCount(tbe.XDim);
    _vecFromMem := true;
  }

  //---------------------------------------------------------------------------
  // Transitions
  //---------------------------------------------------------------------------

  // READ requests

  transition(I, { READ, SPLOAD, VREAD0 }, IV) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    avt_addVecInfoToTBE;
    acb_allocateCacheBlock;
    imr_issueMemReadRequest;
    prq_popRequestQueue;
    pms_profileMissAccess;
  }

  transition(V, READ) {
    smu_setMRU;
    sdc_sendDataFromCache;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(M, READ) {
    smu_setMRU;
    sdc_sendDataFromCache;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(IV, Memory_Data, V) {
    wdc_writeDataToCache;
    smu_setMRU;
    sdm_sendDataFromMem;
    rvm_resetVectorFromMem;
    dtb_deallocateTBE;
    pmq_popMemResponseQueue;
    wua_wakeupAllDependents;
  }
  
  transition({V, M}, SPLOAD) {
    //pah_prefetchAckHit; // TODO don't need this? and acutally prob bad to wait in CPU
    smu_setMRU;
    rsc_remoteStoreFromCache;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }
  
  transition(IV, SP_Mem_Data, V) {
    //pam_prefetchAckMiss; // TODO overhaul this one to remove
    wdc_writeDataToCache;
    smu_setMRU;
    rsm_remoteStoreFromMem;
    rvm_resetVectorFromMem;
    dtb_deallocateTBE;
    pmq_popMemResponseQueue;
    wua_wakeupAllDependents;
  }
  
// vector sends, go to vector, only last request is a non-vector one (like original read)
// TODO might want to have real op go first, but then the other port might mode while going
// ... both have pro-cons, but saved by serialization of message in toSPAD outport (presumably serialized)
// TODO since a prefetch is modeled as a write we place into the st queue, need to ack this
// for the master.
  transition({V, M}, VREAD0) {
    rsc_remoteStoreFromCache;
    ivc_incVectorCount;
    //pah_prefetchAckHit;
  }
  
  transition({V, M}, VREAD1) {
    rsc_remoteStoreFromCache;
    ivc_incVectorCount;
  }
  
  transition({V, M}, VREAD2) {
    smu_setMRU;
    rsc_remoteStoreFromCache;
    rvl_resetVectorFromLLC; // last read (vector or not vector) so reset count
    prq_popRequestQueue;
    pht_profileHitAccess;
  }
  
  transition(IV, VData0) {
    wdc_writeDataToCache
    rsm_remoteStoreFromMem;
    ivt_incVectorCountTBE;
    //pam_prefetchAckMiss;
  }
  
  transition(IV, VData1) {
    rsm_remoteStoreFromMem;
    ivt_incVectorCountTBE;
  }
  
  transition(IV, VData2, V) {
    //wdc_writeDataToCache;
    smu_setMRU;
    rsm_remoteStoreFromMem;
    rvm_resetVectorFromMem;
    dtb_deallocateTBE;
    pmq_popMemResponseQueue;
    wua_wakeupAllDependents;
  }

  transition({IV, MI, IM, IV_LL, IA}, { READ, SPLOAD, VREAD0, VREAD1, VREAD2 }) {
    z_stallAndWait;
  }

  // LL requests

  transition(I, LL, IV_LL) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    acb_allocateCacheBlock;
    imr_issueMemReadRequest;
    prq_popRequestQueue;
    pms_profileMissAccess;
  }

  transition(V, LL) {
    smu_setMRU;
    sor_setLLSCOwnerFromRequest;
    sdc_sendDataFromCache;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(M, LL) {
    smu_setMRU;
    sor_setLLSCOwnerFromRequest;
    sdc_sendDataFromCache;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(IV_LL, Memory_Data, V) {
    wdc_writeDataToCache;
    sot_setLLSCOwnerFromTBE;
    smu_setMRU;
    sdm_sendDataFromMem;
    dtb_deallocateTBE;
    pmq_popMemResponseQueue;
    wua_wakeupAllDependents;
  }

  transition({IV, MI, IM, IV_LL, IA}, LL) {
    z_stallAndWait;
  }

  // WRITE requests

  transition(V, WRITE, M) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    smu_setMRU;
    wdd_writeDirtyDataToCache;
    swa_sendWriteAck;
    dtb_deallocateTBE;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(M, WRITE) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    smu_setMRU;
    wdd_writeDirtyDataToCache;
    swa_sendWriteAck;
    dtb_deallocateTBE;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(I, WRITE, IM) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    sdt_saveDataInTBE;
    acb_allocateCacheBlock;
    imr_issueMemReadRequest;
    prq_popRequestQueue;
    pms_profileMissAccess;
  }

  transition(IM, Memory_Data, M) {
    wdc_writeDataToCache;
    wdt_writeDirtyDataToCacheFromTBE;
    swa_sendWriteAck;
    smu_setMRU;
    dtb_deallocateTBE;
    pmq_popMemResponseQueue;
    wua_wakeupAllDependents;
  }

  transition({IV, MI, IM, IV_LL, IA}, WRITE) {
    z_stallAndWait;
  }

  // SC requests

  transition(I, SC) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    scf_sendFailedSCAck;
    dtb_deallocateTBE;
    prq_popRequestQueue;
    pms_profileMissAccess;
  }

  transition(V, SC, M) {
    hsc_handleSCRequest;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(M, SC) {
    hsc_handleSCRequest;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition({IV, MI, IM, IV_LL, IA}, SC) {
    z_stallAndWait;
  }

  // ATOMIC requests

  transition(V, ATOMIC, M) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    sdt_saveDataInTBE;
    smu_setMRU;
    dat_doAtomicUpdate;
    dtb_deallocateTBE;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(M, ATOMIC) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    sdt_saveDataInTBE;
    smu_setMRU;
    dat_doAtomicUpdate;
    dtb_deallocateTBE;
    prq_popRequestQueue;
    pht_profileHitAccess;
  }

  transition(I, ATOMIC, IA) {
    atb_allocateTBE;
    art_addRequestorToTBE;
    sdt_saveDataInTBE;
    acb_allocateCacheBlock;
    imr_issueMemReadRequest;
    prq_popRequestQueue;
    pms_profileMissAccess;
  }

  transition(IA, Memory_Data, M) {
    wdc_writeDataToCache;
    dat_doAtomicUpdate;
    smu_setMRU;
    dtb_deallocateTBE;
    pmq_popMemResponseQueue;
    wua_wakeupAllDependents;
  }

  transition({IV, MI, IM, IV_LL, IA}, ATOMIC) {
    z_stallAndWait;
  }

  // REPL

  transition({V, I}, Repl, I) {
    dce_deallocateCacheEntry;
  }

  transition(M, Repl, MI) {
    atb_allocateTBE;
    imw_issueMemWriteBackRequest;
    dce_deallocateCacheEntry;
  }

  transition(MI, Memory_Ack, I) {
    dtb_deallocateTBE;
    pmq_popMemResponseQueue;
    wua_wakeupAllDependents;
  }

  transition({IV, MI, IM, IV_LL, IA}, Repl) {
    z_stallAndWait;
  }
  
  transition({V, I, M, IV, MI, IM, IV_LL, IA}, STALL) {
    z_stall;
  }
}
